{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cc4847",
   "metadata": {},
   "source": [
    "# üß™ QRT Leukemia Challenge ‚Äî Notebook d'Exp√©rimentation\n",
    "\n",
    "**Objectif**: Tester des am√©liorations pour d√©passer le score actuel de **0.7111** (GBSA)\n",
    "\n",
    "**Score cible**: 0.7744 (Challenge Winner)\n",
    "\n",
    "---\n",
    "\n",
    "## Historique des Scores\n",
    "\n",
    "| Version | Mod√®le | IPCW C-index | Notes |\n",
    "|---------|--------|--------------|-------|\n",
    "| v1 | Ridge Baseline | 0.6537 | Ignore censure |\n",
    "| v2 | Random Survival Forest | 0.7040 | Grid search optimis√© |\n",
    "| v3 | Gradient Boosting Surv | **0.7111** | Meilleur actuel |\n",
    "| v4 | Ensemble RSF+GBSA | ? | √Ä tester |\n",
    "| v5 | GBSA + More Features | ? | √Ä tester |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfac483",
   "metadata": {},
   "source": [
    "## 1. Setup ‚Äî Chargement des donn√©es et mod√®les de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03087bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration charg√©e\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Configuration et Imports\n",
    "# ============================================================\n",
    "import os, sys, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Mod√®les de survie\n",
    "from sksurv.ensemble import RandomSurvivalForest, GradientBoostingSurvivalAnalysis\n",
    "\n",
    "# Modules locaux\n",
    "from src.config import (\n",
    "    RANDOM_STATE, TAU_YEARS, ID_COL, TARGET_TIME, TARGET_EVENT,\n",
    "    RSF_DEFAULT_PARAMS, RSF_PARAM_GRID\n",
    ")\n",
    "from src.data_loader import load_all_data, merge_train_data, clean_target\n",
    "from src.features import build_molecular_features, get_feature_columns\n",
    "from src.preprocessing import get_default_preprocessor\n",
    "from src.evaluation import to_sksurv_y, ipcw_cindex\n",
    "from src.models import create_rsf_model\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "print(\"‚úì Configuration charg√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17aee61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Donn√©es pr√™tes:\n",
      "  ‚Ä¢ Train: 2538 patients √ó 92 features\n",
      "  ‚Ä¢ Valid: 635 patients\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Chargement et pr√©paration des donn√©es\n",
    "# ============================================================\n",
    "clinical_train, clinical_test, molecular_train, molecular_test, y_train = load_all_data()\n",
    "\n",
    "# Feature engineering mol√©culaire\n",
    "mol_feat_train = build_molecular_features(molecular_train)\n",
    "mol_feat_test = build_molecular_features(molecular_test)\n",
    "\n",
    "# Fusion\n",
    "X_train_full = merge_train_data(clinical_train, mol_feat_train, y_train)\n",
    "X_test_full = clinical_test.merge(mol_feat_test, on=ID_COL, how=\"left\").fillna(0)\n",
    "\n",
    "# Aligner colonnes\n",
    "for col in X_train_full.columns:\n",
    "    if col not in X_test_full.columns:\n",
    "        X_test_full[col] = 0\n",
    "X_test_full = X_test_full[[c for c in X_train_full.columns if c in X_test_full.columns]]\n",
    "\n",
    "train_full = clean_target(X_train_full)\n",
    "feature_cols = get_feature_columns(train_full)\n",
    "\n",
    "# Split\n",
    "train_df, valid_df = train_test_split(\n",
    "    train_full, test_size=0.2, random_state=RANDOM_STATE,\n",
    "    stratify=train_full[TARGET_EVENT]\n",
    ")\n",
    "ytr_s = to_sksurv_y(train_df)\n",
    "yva_s = to_sksurv_y(valid_df)\n",
    "\n",
    "# Preprocessor\n",
    "preprocess = get_default_preprocessor(feature_cols)\n",
    "\n",
    "print(f\"‚úì Donn√©es pr√™tes:\")\n",
    "print(f\"  ‚Ä¢ Train: {train_df.shape[0]} patients √ó {len(feature_cols)} features\")\n",
    "print(f\"  ‚Ä¢ Valid: {valid_df.shape[0]} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2579d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Fonctions utilitaires pr√™tes\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Scores de r√©f√©rence (d√©j√† obtenus dans main.ipynb)\n",
    "# ============================================================\n",
    "REFERENCE_SCORES = {\n",
    "    \"Baseline (Ridge)\": 0.6537,\n",
    "    \"KMeans Clustering\": 0.6182,\n",
    "    \"Random Survival Forest\": 0.7040,\n",
    "    \"Gradient Boosting Surv\": 0.7111,\n",
    "    \"Challenge Winner\": 0.7744\n",
    "}\n",
    "\n",
    "def print_score_comparison(new_score, model_name):\n",
    "    \"\"\"Compare un nouveau score avec les r√©f√©rences\"\"\"\n",
    "    print(f\"\\nüìä {model_name}: {new_score:.4f}\")\n",
    "    print(f\"   vs GBSA (0.7111): {(new_score - 0.7111)*100:+.2f}%\")\n",
    "    print(f\"   vs Winner (0.7744): {(new_score - 0.7744)*100:+.2f}%\")\n",
    "    return new_score\n",
    "\n",
    "print(\"‚úì Fonctions utilitaires pr√™tes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06dc98e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Exp√©rience 1: Ensemble RSF + GBSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9737f8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Entra√Ænement RSF...\n",
      "  RSF: 0.7040\n",
      "üîÑ Entra√Ænement GBSA...\n",
      "  GBSA: 0.7111\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Entra√Ænement des mod√®les de base\n",
    "# ============================================================\n",
    "print(\"üîÑ Entra√Ænement RSF...\")\n",
    "X_train_prep = preprocess.fit_transform(train_df[feature_cols])\n",
    "X_valid_prep = preprocess.transform(valid_df[feature_cols])\n",
    "\n",
    "# RSF\n",
    "rsf = RandomSurvivalForest(\n",
    "    n_estimators=200, min_samples_leaf=20, min_samples_split=10,\n",
    "    max_features=0.5, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "rsf.fit(X_train_prep, ytr_s)\n",
    "rsf_risk = rsf.predict(X_valid_prep)\n",
    "rsf_c = ipcw_cindex(ytr_s, yva_s, rsf_risk)\n",
    "print(f\"  RSF: {rsf_c:.4f}\")\n",
    "\n",
    "# GBSA\n",
    "print(\"üîÑ Entra√Ænement GBSA...\")\n",
    "gbsa = GradientBoostingSurvivalAnalysis(\n",
    "    n_estimators=200, learning_rate=0.1, max_depth=3,\n",
    "    min_samples_split=10, min_samples_leaf=5,\n",
    "    random_state=RANDOM_STATE, verbose=0\n",
    ")\n",
    "gbsa.fit(X_train_prep, ytr_s)\n",
    "gbsa_risk = gbsa.predict(X_valid_prep)\n",
    "gbsa_c = ipcw_cindex(ytr_s, yva_s, gbsa_risk)\n",
    "print(f\"  GBSA: {gbsa_c:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e3829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÄ Test Ensemble RSF + GBSA...\n",
      "\n",
      "  w_gbsa=0.2 -> 0.7085\n",
      "  w_gbsa=0.3 -> 0.7097\n",
      "  w_gbsa=0.4 -> 0.7103\n",
      "  w_gbsa=0.5 -> 0.7102\n",
      "  w_gbsa=0.6 -> 0.7106\n",
      "  w_gbsa=0.7 -> 0.7113\n",
      "  w_gbsa=0.8 -> 0.7118\n",
      "\n",
      "üìä Ensemble (w_gbsa=0.8): 0.7118\n",
      "   vs GBSA (0.7111): +0.07%\n",
      "   vs Winner (0.7744): -6.26%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7117595360786825"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Ensemble: Moyenne pond√©r√©e\n",
    "# ============================================================\n",
    "print(\"üîÄ Test Ensemble RSF + GBSA...\\n\")\n",
    "\n",
    "rsf_norm = MinMaxScaler().fit_transform(rsf_risk.reshape(-1, 1)).flatten()\n",
    "gbsa_norm = MinMaxScaler().fit_transform(gbsa_risk.reshape(-1, 1)).flatten()\n",
    "\n",
    "results_ensemble = {}\n",
    "for w in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "    ensemble = w * gbsa_norm + (1 - w) * rsf_norm\n",
    "    c = ipcw_cindex(ytr_s, yva_s, ensemble)\n",
    "    results_ensemble[w] = c\n",
    "    print(f\"  w_gbsa={w:.1f} -> {c:.4f}\")\n",
    "\n",
    "best_w = max(results_ensemble, key=results_ensemble.get)\n",
    "best_ensemble_c = results_ensemble[best_w]\n",
    "print_score_comparison(best_ensemble_c, f\"Ensemble (w_gbsa={best_w})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e934e3b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Exp√©rience 2: Tuning GBSA avec plus d'arbres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6382130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Tuning GBSA...\n",
      "\n",
      "  [1/18] n=100, lr=0.05, d=2 -> 0.7027\n",
      "  [2/18] n=100, lr=0.05, d=3 -> 0.6968\n",
      "  [3/18] n=100, lr=0.05, d=4 -> 0.7003\n",
      "  [4/18] n=100, lr=0.1, d=2 -> 0.7081\n",
      "  [5/18] n=100, lr=0.1, d=3 -> 0.7052\n",
      "  [6/18] n=100, lr=0.1, d=4 -> 0.7079\n",
      "  [7/18] n=200, lr=0.05, d=2 -> 0.7087\n",
      "  [8/18] n=200, lr=0.05, d=3 -> 0.7052\n",
      "  [9/18] n=200, lr=0.05, d=4 -> 0.7085\n",
      "  [10/18] n=200, lr=0.1, d=2 -> 0.7118\n",
      "  [11/18] n=200, lr=0.1, d=3 -> 0.7111\n",
      "  [12/18] n=200, lr=0.1, d=4 -> 0.7098\n",
      "  [13/18] n=300, lr=0.05, d=2 -> 0.7117\n",
      "  [14/18] n=300, lr=0.05, d=3 -> 0.7088\n",
      "  [15/18] n=300, lr=0.05, d=4 -> 0.7093\n",
      "  [16/18] n=300, lr=0.1, d=2 -> 0.7141\n",
      "  [17/18] n=300, lr=0.1, d=3 -> 0.7116\n",
      "  [18/18] n=300, lr=0.1, d=4 -> 0.7093\n",
      "\n",
      "‚úì Meilleurs params: {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 2}\n",
      "\n",
      "üìä GBSA Tuned: 0.7141\n",
      "   vs GBSA (0.7111): +0.30%\n",
      "   vs Winner (0.7744): -6.03%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7141465240109957"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Grid Search manuel pour GBSA\n",
    "# ============================================================\n",
    "print(\"üéØ Tuning GBSA...\\n\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [2, 3, 4]\n",
    "}\n",
    "\n",
    "best_gbsa_score = 0\n",
    "best_gbsa_params = None\n",
    "\n",
    "from itertools import product\n",
    "total = len(param_grid['n_estimators']) * len(param_grid['learning_rate']) * len(param_grid['max_depth'])\n",
    "i = 0\n",
    "\n",
    "for n_est, lr, depth in product(\n",
    "    param_grid['n_estimators'],\n",
    "    param_grid['learning_rate'],\n",
    "    param_grid['max_depth']\n",
    "):\n",
    "    i += 1\n",
    "    model = GradientBoostingSurvivalAnalysis(\n",
    "        n_estimators=n_est, learning_rate=lr, max_depth=depth,\n",
    "        min_samples_split=10, min_samples_leaf=5,\n",
    "        random_state=RANDOM_STATE, verbose=0\n",
    "    )\n",
    "    model.fit(X_train_prep, ytr_s)\n",
    "    risk = model.predict(X_valid_prep)\n",
    "    c = ipcw_cindex(ytr_s, yva_s, risk)\n",
    "    \n",
    "    if c > best_gbsa_score:\n",
    "        best_gbsa_score = c\n",
    "        best_gbsa_params = {'n_estimators': n_est, 'learning_rate': lr, 'max_depth': depth}\n",
    "    \n",
    "    print(f\"  [{i}/{total}] n={n_est}, lr={lr}, d={depth} -> {c:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úì Meilleurs params: {best_gbsa_params}\")\n",
    "print_score_comparison(best_gbsa_score, \"GBSA Tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c777cb0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Exp√©rience 3: Plus de features g√©n√©tiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fe699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Test avec plus de g√®nes (TOP_GENES=50)...\n",
      "\n",
      "  Nouvelles features: 82 (vs 92 avant)\n",
      "  + -10 nouvelles features\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Augmenter TOP_GENES de 30 √† 50\n",
    "# ============================================================\n",
    "print(\"üß¨ Test avec plus de g√®nes (TOP_GENES=50)...\\n\")\n",
    "\n",
    "# Re-cr√©er les features avec plus de g√®nes\n",
    "mol_feat_train_v2 = build_molecular_features(molecular_train, top_genes=50, top_effects=20)\n",
    "mol_feat_test_v2 = build_molecular_features(molecular_test, top_genes=50, top_effects=20)\n",
    "\n",
    "# Refaire la fusion\n",
    "X_train_v2 = merge_train_data(clinical_train, mol_feat_train_v2, y_train)\n",
    "X_test_v2 = clinical_test.merge(mol_feat_test_v2, on=ID_COL, how=\"left\").fillna(0)\n",
    "\n",
    "for col in X_train_v2.columns:\n",
    "    if col not in X_test_v2.columns:\n",
    "        X_test_v2[col] = 0\n",
    "\n",
    "train_full_v2 = clean_target(X_train_v2)\n",
    "feature_cols_v2 = get_feature_columns(train_full_v2)\n",
    "\n",
    "print(f\"  Nouvelles features: {len(feature_cols_v2)} (vs {len(feature_cols)} avant)\")\n",
    "print(f\"  + {len(feature_cols_v2) - len(feature_cols)} nouvelles features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d65e58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä GBSA + 50 g√®nes: 0.7108\n",
      "   vs GBSA (0.7111): -0.03%\n",
      "   vs Winner (0.7744): -6.36%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7108462613405228"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split et entra√Ænement\n",
    "train_df_v2, valid_df_v2 = train_test_split(\n",
    "    train_full_v2, test_size=0.2, random_state=RANDOM_STATE,\n",
    "    stratify=train_full_v2[TARGET_EVENT]\n",
    ")\n",
    "ytr_v2 = to_sksurv_y(train_df_v2)\n",
    "yva_v2 = to_sksurv_y(valid_df_v2)\n",
    "\n",
    "preprocess_v2 = get_default_preprocessor(feature_cols_v2)\n",
    "X_train_v2_prep = preprocess_v2.fit_transform(train_df_v2[feature_cols_v2])\n",
    "X_valid_v2_prep = preprocess_v2.transform(valid_df_v2[feature_cols_v2])\n",
    "\n",
    "# GBSA avec plus de features\n",
    "gbsa_v2 = GradientBoostingSurvivalAnalysis(\n",
    "    n_estimators=200, learning_rate=0.1, max_depth=3,\n",
    "    min_samples_split=10, min_samples_leaf=5,\n",
    "    random_state=RANDOM_STATE, verbose=0\n",
    ")\n",
    "gbsa_v2.fit(X_train_v2_prep, ytr_v2)\n",
    "gbsa_v2_risk = gbsa_v2.predict(X_valid_v2_prep)\n",
    "gbsa_v2_c = ipcw_cindex(ytr_v2, yva_v2, gbsa_v2_risk)\n",
    "\n",
    "print_score_comparison(gbsa_v2_c, \"GBSA + 50 g√®nes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c56e4d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Exp√©rience 4: Co-mutations (interactions g√®ne-g√®ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ccbbcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Cr√©ation de features de co-mutation...\n",
      "\n",
      "  Co-mutations cr√©√©es: 7\n",
      "    ‚Ä¢ COMUT__TP53_RUNX1: 19 patients\n",
      "    ‚Ä¢ COMUT__ASXL1_TET2: 307 patients\n",
      "    ‚Ä¢ COMUT__DNMT3A_TET2: 134 patients\n",
      "    ‚Ä¢ COMUT__SRSF2_TET2: 299 patients\n",
      "    ‚Ä¢ COMUT__TP53_ASXL1: 30 patients\n",
      "    ‚Ä¢ COMUT__NPM1_FLT3: 15 patients\n",
      "    ‚Ä¢ COMUT__RUNX1_ASXL1: 250 patients\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Ajouter des features de co-mutation\n",
    "# ============================================================\n",
    "print(\"üß¨ Cr√©ation de features de co-mutation...\\n\")\n",
    "\n",
    "# Paires de g√®nes connues pour √™tre importantes en AML/MDS\n",
    "important_gene_pairs = [\n",
    "    ('TP53', 'RUNX1'),\n",
    "    ('ASXL1', 'TET2'),\n",
    "    ('DNMT3A', 'TET2'),\n",
    "    ('SRSF2', 'TET2'),\n",
    "    ('TP53', 'ASXL1'),\n",
    "    ('NPM1', 'FLT3'),\n",
    "    ('RUNX1', 'ASXL1'),\n",
    "]\n",
    "\n",
    "def add_comutation_features(df, gene_cols):\n",
    "    \"\"\"Ajoute des features de co-mutation\"\"\"\n",
    "    df_out = df.copy()\n",
    "    for g1, g2 in important_gene_pairs:\n",
    "        col1 = f'GENE__{g1}'\n",
    "        col2 = f'GENE__{g2}'\n",
    "        if col1 in df.columns and col2 in df.columns:\n",
    "            df_out[f'COMUT__{g1}_{g2}'] = ((df[col1] > 0) & (df[col2] > 0)).astype(int)\n",
    "    return df_out\n",
    "\n",
    "# Appliquer aux donn√©es\n",
    "train_full_v3 = add_comutation_features(train_full, feature_cols)\n",
    "feature_cols_v3 = [c for c in train_full_v3.columns if c not in [ID_COL, TARGET_TIME, TARGET_EVENT]]\n",
    "\n",
    "comut_cols = [c for c in feature_cols_v3 if c.startswith('COMUT__')]\n",
    "print(f\"  Co-mutations cr√©√©es: {len(comut_cols)}\")\n",
    "for c in comut_cols:\n",
    "    print(f\"    ‚Ä¢ {c}: {train_full_v3[c].sum()} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d96594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä GBSA + Co-mutations: 0.7111\n",
      "   vs GBSA (0.7111): +0.00%\n",
      "   vs Winner (0.7744): -6.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7111113627068091"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entra√Ænement avec co-mutations\n",
    "train_df_v3, valid_df_v3 = train_test_split(\n",
    "    train_full_v3, test_size=0.2, random_state=RANDOM_STATE,\n",
    "    stratify=train_full_v3[TARGET_EVENT]\n",
    ")\n",
    "ytr_v3 = to_sksurv_y(train_df_v3)\n",
    "yva_v3 = to_sksurv_y(valid_df_v3)\n",
    "\n",
    "preprocess_v3 = get_default_preprocessor(feature_cols_v3)\n",
    "X_train_v3_prep = preprocess_v3.fit_transform(train_df_v3[feature_cols_v3])\n",
    "X_valid_v3_prep = preprocess_v3.transform(valid_df_v3[feature_cols_v3])\n",
    "\n",
    "gbsa_v3 = GradientBoostingSurvivalAnalysis(\n",
    "    n_estimators=200, learning_rate=0.1, max_depth=3,\n",
    "    min_samples_split=10, min_samples_leaf=5,\n",
    "    random_state=RANDOM_STATE, verbose=0\n",
    ")\n",
    "gbsa_v3.fit(X_train_v3_prep, ytr_v3)\n",
    "gbsa_v3_risk = gbsa_v3.predict(X_valid_v3_prep)\n",
    "gbsa_v3_c = ipcw_cindex(ytr_v3, yva_v3, gbsa_v3_risk)\n",
    "\n",
    "print_score_comparison(gbsa_v3_c, \"GBSA + Co-mutations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f19ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. R√©capitulatif des Exp√©riences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea45b762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "   R√âCAPITULATIF DES EXP√âRIENCES\n",
      "======================================================================\n",
      "  Challenge Winner          ‚îÇ 0.7744 ‚îÇ +0.0000 ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  GBSA Tuned                ‚îÇ 0.7141 ‚îÇ -0.0603 ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Ensemble RSF+GBSA         ‚îÇ 0.7118 ‚îÇ -0.0626 ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  GBSA + Co-mutations       ‚îÇ 0.7111 ‚îÇ -0.0633 ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Baseline GBSA             ‚îÇ 0.7111 ‚îÇ -0.0633 ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  GBSA + 50 g√®nes           ‚îÇ 0.7108 ‚îÇ -0.0636 ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Tableau r√©capitulatif\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"   R√âCAPITULATIF DES EXP√âRIENCES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "experiments = {\n",
    "    \"Baseline GBSA\": REFERENCE_SCORES[\"Gradient Boosting Surv\"],\n",
    "}\n",
    "\n",
    "# Ajouter les r√©sultats si disponibles\n",
    "if 'best_ensemble_c' in dir():\n",
    "    experiments[\"Ensemble RSF+GBSA\"] = best_ensemble_c\n",
    "if 'best_gbsa_score' in dir():\n",
    "    experiments[\"GBSA Tuned\"] = best_gbsa_score\n",
    "if 'gbsa_v2_c' in dir():\n",
    "    experiments[\"GBSA + 50 g√®nes\"] = gbsa_v2_c\n",
    "if 'gbsa_v3_c' in dir():\n",
    "    experiments[\"GBSA + Co-mutations\"] = gbsa_v3_c\n",
    "\n",
    "experiments[\"Challenge Winner\"] = 0.7744\n",
    "\n",
    "for exp, score in sorted(experiments.items(), key=lambda x: x[1], reverse=True):\n",
    "    bar = \"‚ñà\" * int(score * 40)\n",
    "    gap = score - 0.7744\n",
    "    print(f\"  {exp:25s} ‚îÇ {score:.4f} ‚îÇ {gap:+.4f} ‚îÇ {bar}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "best_exp = max(experiments, key=experiments.get)\n",
    "if best_exp != \"Challenge Winner\":\n",
    "    print(f\"\\nüèÜ Meilleure exp√©rience: {best_exp} ({experiments[best_exp]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee09cd6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Prochaines √âtapes\n",
    "\n",
    "### √Ä tester :\n",
    "- [ ] CoxPH avec ElasticNet regularization\n",
    "- [ ] Parser CYTOGENETICS (del(5q), -7, complex karyotype)\n",
    "- [ ] Stacking avec meta-learner\n",
    "- [ ] XGBoost/LightGBM avec AFT (Accelerated Failure Time)\n",
    "- [ ] Neural Network (DeepSurv)\n",
    "\n",
    "### Notes :\n",
    "- Mettre √† jour le tableau r√©capitulatif apr√®s chaque exp√©rience\n",
    "- Sauvegarder les meilleurs mod√®les avec joblib\n",
    "- Reporter les r√©sultats dans main.ipynb une fois valid√©s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
