# QRT Data Challenge 2024 â€” Leukemia Risk Prediction

<p align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Logo-gustave-roussy.jpg/1200px-Logo-gustave-roussy.jpg" alt="Gustave Roussy" width="200"/>
  <img src="https://upload.wikimedia.org/wikipedia/en/thumb/3/3f/Qube_Research_%26_Technologies_Logo.svg/1200px-Qube_Research_%26_Technologies_Logo.svg.png" alt="QRT" width="150" style="margin-left: 20px;"/>
</p>

> **Objectif**: PrÃ©dire le risque de dÃ©cÃ¨s pour des patients atteints de leucÃ©mie myÃ©loÃ¯de en utilisant des donnÃ©es cliniques et molÃ©culaires.

## ğŸ“‹ Table des MatiÃ¨res

- [Installation Rapide](#-installation-rapide)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [MÃ©thodologie](#-mÃ©thodologie)
- [RÃ©sultats](#-rÃ©sultats)
- [Historique des Modifications](#-historique-des-modifications)

---

## ğŸš€ Installation Rapide

### PrÃ©requis

- Python 3.9+
- pip ou conda

### Installation

```bash
# 1. Cloner le repository
git clone https://github.com/chenenen13/QRT-Leukemia-DataChallenge.git
cd QRT-Leukemia-DataChallenge

# 2. CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou: venv\Scripts\activate  # Windows

# 3. Installer les dÃ©pendances
pip install -r requirements.txt
```

### DÃ©pendances principales

| Package | Version | Description |
|---------|---------|-------------|
| numpy | â‰¥1.24.0 | Calculs numÃ©riques |
| pandas | â‰¥2.0.0 | Manipulation de donnÃ©es |
| scikit-learn | â‰¥1.3.0 | Machine learning |
| scikit-survival | â‰¥0.22.0 | ModÃ¨les de survie |
| lightgbm | â‰¥4.0.0 | Gradient boosting |
| numba | â‰¥0.58.0 | Optimisation JIT |

---

## ğŸ’» Utilisation

### Option 1: ExÃ©cuter le rapport complet

```bash
# Ouvrir le notebook principal (rapport)
jupyter notebook main.ipynb
```

Ce notebook contient:
- Analyse exploratoire complÃ¨te
- Tous les modÃ¨les (baseline, clustering, RSF)
- Visualisations et interprÃ©tations
- GÃ©nÃ©ration du fichier de soumission

### Option 2: Utiliser les modules Python

```python
from src.data_loader import load_all_data
from src.features import build_molecular_features
from src.models import create_rsf_model
from src.evaluation import ipcw_cindex

# Charger les donnÃ©es
clinical_train, clinical_test, molecular_train, molecular_test, y_train = load_all_data()

# Feature engineering
mol_features = build_molecular_features(molecular_train)

# CrÃ©er et entraÃ®ner un modÃ¨le
model = create_rsf_model({"n_estimators": 400})
# ...
```

### Option 3: Notebook de dÃ©veloppement

```bash
# Pour le notebook de dÃ©veloppement dÃ©taillÃ©
jupyter notebook DataChallenge_ML.ipynb
```

### GÃ©nÃ©rer une soumission

AprÃ¨s exÃ©cution de `main.ipynb` ou `DataChallenge_ML.ipynb`:

```bash
# Le fichier submission.csv est crÃ©Ã© Ã  la racine
cat submission.csv | head
```

Format attendu:
```csv
ID,risk_score
P123456,2.345
P123457,1.234
...
```

---

## ğŸ“ Structure du Projet

```
QRT-Leukemia-DataChallenge/
â”‚
â”œâ”€â”€ ğŸ“Š data/                        # DonnÃ©es brutes
â”‚   â”œâ”€â”€ clinical_train.csv          # DonnÃ©es cliniques (train)
â”‚   â”œâ”€â”€ clinical_test.csv           # DonnÃ©es cliniques (test)
â”‚   â”œâ”€â”€ molecular_train.csv         # Mutations gÃ©nÃ©tiques (train)
â”‚   â”œâ”€â”€ molecular_test.csv          # Mutations gÃ©nÃ©tiques (test)
â”‚   â””â”€â”€ target_train.csv            # Labels (OS_YEARS, OS_STATUS)
â”‚
â”œâ”€â”€ ğŸ“¦ src/                         # Modules Python
â”‚   â”œâ”€â”€ __init__.py                 # Package init
â”‚   â”œâ”€â”€ config.py                   # Configuration et constantes
â”‚   â”œâ”€â”€ data_loader.py              # Chargement et validation des donnÃ©es
â”‚   â”œâ”€â”€ features.py                 # Feature engineering
â”‚   â”œâ”€â”€ preprocessing.py            # Pipelines sklearn
â”‚   â”œâ”€â”€ models.py                   # DÃ©finitions des modÃ¨les
â”‚   â”œâ”€â”€ evaluation.py               # MÃ©triques et cross-validation
â”‚   â”œâ”€â”€ optimization.py             # Fonctions Numba optimisÃ©es
â”‚   â””â”€â”€ visualization.py            # Graphiques et visualisations
â”‚
â”œâ”€â”€ ğŸ““ main.ipynb                   # Rapport principal (Ã  soumettre)
â”œâ”€â”€ ğŸ““ DataChallenge_ML.ipynb       # Notebook de dÃ©veloppement
â”œâ”€â”€ ğŸ““ Benchmark_nqBJ7fO.ipynb      # Benchmark fourni par QRT
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ submission.csv               # Fichier de soumission
â””â”€â”€ ğŸ“„ README.md                    # Ce fichier
```

### Description des modules `src/`

| Module | Description |
|--------|-------------|
| `config.py` | Constantes, chemins, hyperparamÃ¨tres par dÃ©faut |
| `data_loader.py` | Fonctions de chargement CSV, validation, fusion des datasets |
| `features.py` | AgrÃ©gation des mutations au niveau patient, extraction de features |
| `preprocessing.py` | Pipelines sklearn (imputation, scaling, TF-IDF, SVD) |
| `models.py` | Classes de modÃ¨les (Baseline, Clustering, RSF) |
| `evaluation.py` | IPCW C-index, cross-validation, grid search |
| `optimization.py` | Fonctions Numba pour calculs intensifs |
| `visualization.py` | Graphiques matplotlib pour le rapport |

---

## ğŸ”¬ MÃ©thodologie

### DonnÃ©es

- **Train**: 3,323 patients avec labels (OS_YEARS, OS_STATUS)
- **Test**: 1,193 patients Ã  prÃ©dire
- **24 centres cliniques**

### Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DonnÃ©es    â”‚ â”€â”€â–¶ â”‚   Feature      â”‚ â”€â”€â–¶ â”‚  Preprocess  â”‚
â”‚   Brutes     â”‚     â”‚   Engineering  â”‚     â”‚  Pipeline    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Submission  â”‚ â—€â”€â”€ â”‚   Ã‰valuation   â”‚ â—€â”€â”€ â”‚   ModÃ¨les    â”‚
â”‚  risk_score  â”‚     â”‚   IPCW C-index â”‚     â”‚   Survie     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ModÃ¨les implÃ©mentÃ©s

1. **Baseline (Ridge Regression)**: RÃ©gression sur OS_YEARS, ignore la censure
2. **KMeans Clustering**: Non-supervisÃ©, risque par mÃ©diane de cluster
3. **Random Survival Forest**: GÃ¨re la censure, hyperparamÃ¨tres optimisÃ©s

### MÃ©trique

**IPCW C-index** (Ï„ = 7 ans): Mesure la capacitÃ© Ã  ordonner correctement les paires de patients selon leur survie.

---

## ğŸ“ˆ RÃ©sultats

| ModÃ¨le | IPCW C-index (validation) |
|--------|---------------------------|
| Baseline (Ridge) | ~0.64 |
| KMeans Clustering | ~0.62 |
| **Random Survival Forest** | **~0.70** |

### Features les plus importantes

1. `BM_BLAST` (blastes moelle osseuse)
2. `PLT` (plaquettes)
3. `HB` (hÃ©moglobine)
4. `n_mut` (nombre de mutations)
5. `vaf_mean` (VAF moyen)

---

## ğŸ“ Historique des Modifications

### Version 2.0 (Actuelle) â€” Restructuration complÃ¨te

#### Changements majeurs

| Avant (`DataChallenge_ML.ipynb` v1) | AprÃ¨s (v2) |
|-------------------------------------|------------|
| Chargement via URL GitHub | Chargement local (`data/`) |
| Fonctions dÃ©finies dans le notebook | Modules Python dans `src/` |
| Pas d'optimisation | Fonctions Numba JIT |
| Code monolithique | Architecture modulaire |
| Pas de requirements.txt | requirements.txt complet |

#### DÃ©tail des modifications

##### 1. **Imports des donnÃ©es** (Cellule 5 â†’ `src/data_loader.py`)

**Avant:**
```python
BASE_URL = "https://raw.githubusercontent.com/.../main/data"
clinical_train = pd.read_csv(f"{BASE_URL}/clinical_train.csv")
```

**AprÃ¨s:**
```python
from src.data_loader import load_all_data
clinical_train, clinical_test, molecular_train, molecular_test, y_train = load_all_data()
```

##### 2. **Feature Engineering** (Cellules 10-11 â†’ `src/features.py`)

**Avant:** Fonction `build_molecular_features()` dÃ©finie dans le notebook (50+ lignes)

**AprÃ¨s:** Module dÃ©diÃ© avec fonctions rÃ©utilisables
```python
from src.features import build_molecular_features, get_feature_columns
```

##### 3. **Preprocessing** (Cellule 18 â†’ `src/preprocessing.py`)

**Avant:** ColumnTransformer dÃ©fini inline avec 30+ lignes

**AprÃ¨s:**
```python
from src.preprocessing import get_default_preprocessor
preprocess = get_default_preprocessor(feature_cols)
```

##### 4. **Ã‰valuation** (Cellules 27-28 â†’ `src/evaluation.py`)

**Avant:** Fonctions `to_sksurv_y()`, `ipcw_cindex()` dans le notebook

**AprÃ¨s:** Module avec grid search et permutation importance
```python
from src.evaluation import ipcw_cindex, grid_search_survival, permutation_importance_survival
```

##### 5. **ModÃ¨les** (Cellules 30-37 â†’ `src/models.py`)

**Avant:** Code inline pour chaque modÃ¨le

**AprÃ¨s:** Classes et factories
```python
from src.models import BaselineRiskModel, ClusteringRiskModel, create_rsf_model
```

##### 6. **Optimisation Numba** (Nouveau â†’ `src/optimization.py`)

Fonctions JIT-compilÃ©es pour les calculs lourds:
- `fast_cindex()` â€” C-index parallÃ©lisÃ©
- `fast_vaf_stats()` â€” Statistiques VAF par patient
- `fast_pairwise_euclidean()` â€” Distances euclidiennes
- `fast_aggregate_by_id()` â€” AgrÃ©gation parallÃ¨le

##### 7. **Visualisation** (Nouveau â†’ `src/visualization.py`)

Fonctions de plotting standardisÃ©es:
- `plot_survival_distribution()`
- `plot_feature_importance()`
- `plot_model_comparison()`
- `plot_cluster_survival()`

##### 8. **Cellules supprimÃ©es**

Les cellules de debugging suivantes ont Ã©tÃ© retirÃ©es:
- VÃ©rification de types intermÃ©diaires
- Tests de preprocessing
- Cellules vides

#### Avantages de la nouvelle architecture

| Aspect | AmÃ©lioration |
|--------|--------------|
| **MaintenabilitÃ©** | Code modulaire, facile Ã  modifier |
| **RÃ©utilisabilitÃ©** | Modules importables dans d'autres projets |
| **Performance** | Optimisations Numba pour calculs intensifs |
| **TestabilitÃ©** | Fonctions isolÃ©es, faciles Ã  tester |
| **ReproductibilitÃ©** | Configuration centralisÃ©e dans `config.py` |

---

## ğŸ“š RÃ©fÃ©rences

- [scikit-survival Documentation](https://scikit-survival.readthedocs.io/)
- [IPCW C-index](https://scikit-survival.readthedocs.io/en/stable/api/generated/sksurv.metrics.concordance_index_ipcw.html)
- [Random Survival Forests](https://arxiv.org/abs/0811.1645)
- [Cox Proportional Hazards](https://en.wikipedia.org/wiki/Proportional_hazards_model)

---

## ğŸ“„ Licence

Ce projet est dÃ©veloppÃ© dans le cadre du QRT Data Challenge 2024 en partenariat avec l'Institut Gustave Roussy.

---

<p align="center">
  <b>QRT Data Challenge 2024</b><br>
  En partenariat avec l'Institut Gustave Roussy
</p>