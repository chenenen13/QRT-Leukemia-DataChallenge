# QRT Data Challenge 2024 â€” Leukemia Risk Prediction

<p align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Logo-gustave-roussy.jpg/1200px-Logo-gustave-roussy.jpg" alt="Gustave Roussy" width="200"/>
  <img src="https://upload.wikimedia.org/wikipedia/en/thumb/3/3f/Qube_Research_%26_Technologies_Logo.svg/1200px-Qube_Research_%26_Technologies_Logo.svg.png" alt="QRT" width="150" style="margin-left: 20px;"/>
</p>

> **Objectif**: PrÃ©dire le risque de dÃ©cÃ¨s pour des patients atteints de leucÃ©mie myÃ©loÃ¯de en utilisant des donnÃ©es cliniques et molÃ©culaires.

## ğŸ† RÃ©sultats Actuels

| ModÃ¨le | IPCW C-index | Status |
|--------|--------------|--------|
| **Gradient Boosting Survival** | **0.7111** | âœ… Meilleur modÃ¨le |
| Random Survival Forest | 0.7040 | âœ… TestÃ© |
| Baseline (Ridge) | 0.6537 | âœ… RÃ©fÃ©rence |
| KMeans Clustering | 0.6182 | âœ… TestÃ© |
| Challenge Winner | 0.7744 | ğŸ¯ Objectif |

> **Gap Ã  combler**: -0.063 (~6%) pour atteindre le score du winner

## ğŸ“‹ Table des MatiÃ¨res

- [RÃ©sultats Actuels](#-rÃ©sultats-actuels)
- [Installation Rapide](#-installation-rapide)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [MÃ©thodologie](#-mÃ©thodologie)
- [ModÃ¨les ImplÃ©mentÃ©s](#-modÃ¨les-implÃ©mentÃ©s)
- [ExpÃ©riences en Cours](#-expÃ©riences-en-cours)
- [Historique des Modifications](#-historique-des-modifications)

---

## ğŸš€ Installation Rapide

### PrÃ©requis

- Python 3.9+
- pip ou conda

### Installation

```bash
# 1. Cloner le repository
git clone https://github.com/chenenen13/QRT-Leukemia-DataChallenge.git
cd QRT-Leukemia-DataChallenge

# 2. CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou: venv\Scripts\activate  # Windows

# 3. Installer les dÃ©pendances
pip install -r requirements.txt
```

### DÃ©pendances principales

| Package | Version | Description |
|---------|---------|-------------|
| numpy | â‰¥1.24.0 | Calculs numÃ©riques |
| pandas | â‰¥2.0.0 | Manipulation de donnÃ©es |
| scikit-learn | â‰¥1.3.0 | Machine learning |
| scikit-survival | â‰¥0.22.0 | ModÃ¨les de survie |
| lightgbm | â‰¥4.0.0 | Gradient boosting |
| numba | â‰¥0.58.0 | Optimisation JIT |

---

## ğŸ’» Utilisation

### Option 1: Voir le rapport final

```bash
# Ouvrir le notebook principal (rÃ©sultats documentÃ©s)
jupyter notebook main.ipynb
```

Ce notebook contient:
- âœ… Analyse exploratoire complÃ¨te
- âœ… Tous les modÃ¨les testÃ©s (Baseline â†’ GBSA)
- âœ… Visualisations et interprÃ©tations
- âœ… GÃ©nÃ©ration du fichier de soumission

### Option 2: Tester des amÃ©liorations

```bash
# Ouvrir le notebook d'expÃ©rimentation
jupyter notebook experiments.ipynb
```

Ce notebook contient:
- ğŸ§ª Tests d'ensemble RSF + GBSA
- ğŸ§ª Tuning GBSA avec grid search Ã©tendu
- ğŸ§ª Tests avec plus de features gÃ©nÃ©tiques
- ğŸ§ª Features de co-mutations

### Option 3: Utiliser les modules Python

```python
from src.data_loader import load_all_data
from src.features import build_molecular_features
from src.models import create_rsf_model
from src.evaluation import ipcw_cindex
from sksurv.ensemble import GradientBoostingSurvivalAnalysis

# Charger les donnÃ©es
clinical_train, clinical_test, molecular_train, molecular_test, y_train = load_all_data()

# Feature engineering
mol_features = build_molecular_features(molecular_train)

# Meilleur modÃ¨le : Gradient Boosting Survival
gbsa = GradientBoostingSurvivalAnalysis(n_estimators=200, learning_rate=0.1, max_depth=3)
```

### Option 4: Notebook de dÃ©veloppement (legacy)

```bash
# Pour le notebook de dÃ©veloppement dÃ©taillÃ©
jupyter notebook DataChallenge_ML.ipynb
```

### GÃ©nÃ©rer une soumission

AprÃ¨s exÃ©cution de `main.ipynb` ou `DataChallenge_ML.ipynb`:

```bash
# Le fichier submission.csv est crÃ©Ã© Ã  la racine
cat submission.csv | head
```

Format attendu:
```csv
ID,risk_score
P123456,2.345
P123457,1.234
...
```

---

## ğŸ“ Structure du Projet

```
QRT-Leukemia-DataChallenge/
â”‚
â”œâ”€â”€ ğŸ“Š data/                        # DonnÃ©es brutes
â”‚   â”œâ”€â”€ clinical_train.csv          # DonnÃ©es cliniques (train)
â”‚   â”œâ”€â”€ clinical_test.csv           # DonnÃ©es cliniques (test)
â”‚   â”œâ”€â”€ molecular_train.csv         # Mutations gÃ©nÃ©tiques (train)
â”‚   â”œâ”€â”€ molecular_test.csv          # Mutations gÃ©nÃ©tiques (test)
â”‚   â””â”€â”€ target_train.csv            # Labels (OS_YEARS, OS_STATUS)
â”‚
â”œâ”€â”€ ğŸ“¦ src/                         # Modules Python
â”‚   â”œâ”€â”€ __init__.py                 # Package init
â”‚   â”œâ”€â”€ config.py                   # Configuration et constantes
â”‚   â”œâ”€â”€ data_loader.py              # Chargement et validation des donnÃ©es
â”‚   â”œâ”€â”€ features.py                 # Feature engineering
â”‚   â”œâ”€â”€ preprocessing.py            # Pipelines sklearn
â”‚   â”œâ”€â”€ models.py                   # DÃ©finitions des modÃ¨les
â”‚   â”œâ”€â”€ evaluation.py               # MÃ©triques et cross-validation
â”‚   â”œâ”€â”€ optimization.py             # Fonctions Numba optimisÃ©es
â”‚   â””â”€â”€ visualization.py            # Graphiques et visualisations
â”‚
â”œâ”€â”€ ğŸ““ main.ipynb                   # Rapport principal (rÃ©sultats finaux)
â”œâ”€â”€ ğŸ““ experiments.ipynb            # Notebook d'expÃ©rimentation (tests avancÃ©s)
â”œâ”€â”€ ğŸ““ DataChallenge_ML.ipynb       # Notebook de dÃ©veloppement (legacy)
â”œâ”€â”€ ğŸ““ Benchmark_nqBJ7fO.ipynb      # Benchmark fourni par QRT
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ submission.csv               # Fichier de soumission
â””â”€â”€ ğŸ“„ README.md                    # Ce fichier
```

### Notebooks

| Notebook | Description | Quand l'utiliser |
|----------|-------------|------------------|
| **main.ipynb** | Rapport final documentÃ© avec tous les rÃ©sultats | Voir les rÃ©sultats finaux, gÃ©nÃ©rer la soumission |
| **experiments.ipynb** | Tests d'amÃ©lioration (ensemble, tuning, etc.) | Tester de nouvelles idÃ©es |
| DataChallenge_ML.ipynb | Notebook original de dÃ©veloppement | RÃ©fÃ©rence historique |

### Description des modules `src/`

| Module | Description |
|--------|-------------|
| `config.py` | Constantes, chemins, hyperparamÃ¨tres par dÃ©faut |
| `data_loader.py` | Fonctions de chargement CSV, validation, fusion des datasets |
| `features.py` | AgrÃ©gation des mutations au niveau patient, extraction de features |
| `preprocessing.py` | Pipelines sklearn (imputation, scaling, TF-IDF, SVD) |
| `models.py` | Classes de modÃ¨les (Baseline, Clustering, RSF) |
| `evaluation.py` | IPCW C-index, cross-validation, grid search |
| `optimization.py` | Fonctions Numba pour calculs intensifs |
| `visualization.py` | Graphiques matplotlib pour le rapport |

---

## ğŸ”¬ MÃ©thodologie

### DonnÃ©es

- **Train**: 3,323 patients avec labels (OS_YEARS, OS_STATUS)
- **Test**: 1,193 patients Ã  prÃ©dire
- **24 centres cliniques**

### Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DonnÃ©es    â”‚ â”€â”€â–¶ â”‚   Feature      â”‚ â”€â”€â–¶ â”‚  Preprocess  â”‚
â”‚   Brutes     â”‚     â”‚   Engineering  â”‚     â”‚  Pipeline    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Submission  â”‚ â—€â”€â”€ â”‚   Ã‰valuation   â”‚ â—€â”€â”€ â”‚   ModÃ¨les    â”‚
â”‚  risk_score  â”‚     â”‚   IPCW C-index â”‚     â”‚   Survie     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ModÃ¨les implÃ©mentÃ©s

1. **Baseline (Ridge Regression)**: RÃ©gression sur OS_YEARS, ignore la censure â†’ **0.6537**
2. **KMeans Clustering**: Non-supervisÃ©, risque par mÃ©diane de cluster â†’ **0.6182**
3. **Random Survival Forest**: GÃ¨re la censure, hyperparamÃ¨tres optimisÃ©s â†’ **0.7040**
4. **Gradient Boosting Survival**: Meilleur modÃ¨le actuel â†’ **0.7111** âœ…

### MÃ©trique

**IPCW C-index** (Ï„ = 7 ans): Mesure la capacitÃ© Ã  ordonner correctement les paires de patients selon leur survie, en tenant compte de la censure Ã  droite.

$$C = \frac{\text{Paires Concordantes}}{\text{Paires Comparables}}$$

- **C = 1**: Classement parfait
- **C = 0.5**: ModÃ¨le alÃ©atoire

---

## ğŸ§ª ModÃ¨les ImplÃ©mentÃ©s

### 1. Baseline Ridge Regression (0.6537)

RÃ©gression linÃ©aire rÃ©gularisÃ©e sur `OS_YEARS`. Simple mais **ignore la censure** (patients encore en vie traitÃ©s comme dÃ©cÃ©dÃ©s).

```python
from src.models import BaselineRiskModel
baseline = BaselineRiskModel(preprocessor=preprocess, alpha=1.0)
```

### 2. KMeans Clustering (0.6182)

Approche non-supervisÃ©e : cluster les patients, puis assigne un risque basÃ© sur la survie mÃ©diane de chaque cluster.

```python
from src.models import ClusteringRiskModel
cluster_model = ClusteringRiskModel(preprocessor=preprocess, n_clusters=5)
```

### 3. Random Survival Forest (0.7040)

ForÃªt alÃ©atoire adaptÃ©e Ã  l'analyse de survie. GÃ¨re correctement la **censure Ã  droite**.

**HyperparamÃ¨tres optimisÃ©s :**
- `n_estimators`: 200-300
- `min_samples_leaf`: 10-20
- `max_features`: 0.5

```python
from sksurv.ensemble import RandomSurvivalForest
rsf = RandomSurvivalForest(n_estimators=200, min_samples_leaf=20, random_state=42)
```

### 4. Gradient Boosting Survival â­ (0.7111)

**Meilleur modÃ¨le actuel.** Gradient boosting adaptÃ© Ã  la survie, souvent meilleur que RSF.

**HyperparamÃ¨tres :**
- `n_estimators`: 200
- `learning_rate`: 0.1
- `max_depth`: 3

```python
from sksurv.ensemble import GradientBoostingSurvivalAnalysis
gbsa = GradientBoostingSurvivalAnalysis(n_estimators=200, learning_rate=0.1, max_depth=3)
```

---

## ğŸ”¬ ExpÃ©riences en Cours

Voir **experiments.ipynb** pour les tests d'amÃ©lioration.

### ExpÃ©riences dÃ©jÃ  implÃ©mentÃ©es

| # | ExpÃ©rience | Description | Status |
|---|------------|-------------|--------|
| 1 | Ensemble RSF + GBSA | Moyenne pondÃ©rÃ©e des deux modÃ¨les | ğŸ§ª Ã€ tester |
| 2 | GBSA Tuning | Grid search plus large (n_estimators, learning_rate, max_depth) | ğŸ§ª Ã€ tester |
| 3 | Plus de gÃ¨nes | Augmenter TOP_GENES de 30 Ã  50 | ğŸ§ª Ã€ tester |
| 4 | Co-mutations | Features d'interaction gÃ¨ne-gÃ¨ne (ex: TP53 + RUNX1) | ğŸ§ª Ã€ tester |

### IdÃ©es Ã  explorer

- [ ] **CoxPH avec ElasticNet** â€” ModÃ¨le de Cox rÃ©gularisÃ©
- [ ] **Parser CYTOGENETICS** â€” Extraire del(5q), -7, complex karyotype
- [ ] **Stacking** â€” Meta-learner sur les prÃ©dictions des modÃ¨les
- [ ] **XGBoost AFT** â€” Accelerated Failure Time avec XGBoost
- [ ] **DeepSurv** â€” RÃ©seau de neurones pour la survie

---

## ğŸ“ˆ RÃ©sultats DÃ©taillÃ©s

| ModÃ¨le | IPCW C-index | Gap vs Winner | Commentaire |
|--------|--------------|---------------|-------------|
| **Gradient Boosting Surv** | **0.7111** | -0.063 | âœ… Meilleur modÃ¨le |
| Random Survival Forest | 0.7040 | -0.070 | Bon modÃ¨le de survie |
| Baseline (Ridge) | 0.6537 | -0.121 | Ignore la censure |
| KMeans Clustering | 0.6182 | -0.156 | Non-supervisÃ© |
| Challenge Winner | 0.7744 | â€” | ğŸ¯ Objectif |

### Progression des scores

```
Baseline      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.6537
KMeans        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.6182
RSF           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  0.7040
GBSA          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘  0.7111 â† Actuel
Winner        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  0.7744 â† Objectif
```

### Features les plus importantes

| Rang | Feature | Description | Impact |
|------|---------|-------------|--------|
| 1 | `BM_BLAST` | Blastes moelle osseuse (%) | TrÃ¨s Ã©levÃ© |
| 2 | `PLT` | Plaquettes (Giga/L) | Ã‰levÃ© |
| 3 | `HB` | HÃ©moglobine (g/dL) | Ã‰levÃ© |
| 4 | `n_mut` | Nombre total de mutations | ModÃ©rÃ© |
| 5 | `vaf_mean` | VAF moyen des mutations | ModÃ©rÃ© |
| 6 | `WBC` | Globules blancs (Giga/L) | ModÃ©rÃ© |
| 7 | `GENE__TP53` | Mutation TP53 (binaire) | Cliniquement important |

---

## ğŸ“ Historique des Modifications

### Version 2.1 (Janvier 2026) â€” Gradient Boosting + ExpÃ©riences

#### NouveautÃ©s

- âœ… **Gradient Boosting Survival** â€” Nouveau meilleur modÃ¨le (0.7111 vs 0.7040 RSF)
- âœ… **experiments.ipynb** â€” Notebook dÃ©diÃ© aux expÃ©riences
- âœ… **Optimisation Grid Search** â€” RÃ©duction de 72 Ã  16 fits, mode fast
- âœ… **Fix alignement colonnes** â€” Correction du bug KeyError sur test set

#### Scores atteints

| Ã‰tape | Score | AmÃ©lioration |
|-------|-------|--------------|
| v1 Baseline | 0.6537 | â€” |
| v2 RSF | 0.7040 | +0.050 |
| v2.1 GBSA | **0.7111** | +0.007 |

### Version 2.0 â€” Restructuration complÃ¨te

#### Changements majeurs

| Avant (`DataChallenge_ML.ipynb` v1) | AprÃ¨s (v2) |
|-------------------------------------|------------|
| Chargement via URL GitHub | Chargement local (`data/`) |
| Fonctions dÃ©finies dans le notebook | Modules Python dans `src/` |
| Pas d'optimisation | Fonctions Numba JIT |
| Code monolithique | Architecture modulaire |
| Pas de requirements.txt | requirements.txt complet |

#### DÃ©tail des modifications

##### 1. **Imports des donnÃ©es** (Cellule 5 â†’ `src/data_loader.py`)

**Avant:**
```python
BASE_URL = "https://raw.githubusercontent.com/.../main/data"
clinical_train = pd.read_csv(f"{BASE_URL}/clinical_train.csv")
```

**AprÃ¨s:**
```python
from src.data_loader import load_all_data
clinical_train, clinical_test, molecular_train, molecular_test, y_train = load_all_data()
```

##### 2. **Feature Engineering** (Cellules 10-11 â†’ `src/features.py`)

**Avant:** Fonction `build_molecular_features()` dÃ©finie dans le notebook (50+ lignes)

**AprÃ¨s:** Module dÃ©diÃ© avec fonctions rÃ©utilisables
```python
from src.features import build_molecular_features, get_feature_columns
```

##### 3. **Preprocessing** (Cellule 18 â†’ `src/preprocessing.py`)

**Avant:** ColumnTransformer dÃ©fini inline avec 30+ lignes

**AprÃ¨s:**
```python
from src.preprocessing import get_default_preprocessor
preprocess = get_default_preprocessor(feature_cols)
```

##### 4. **Ã‰valuation** (Cellules 27-28 â†’ `src/evaluation.py`)

**Avant:** Fonctions `to_sksurv_y()`, `ipcw_cindex()` dans le notebook

**AprÃ¨s:** Module avec grid search et permutation importance
```python
from src.evaluation import ipcw_cindex, grid_search_survival, permutation_importance_survival
```

##### 5. **ModÃ¨les** (Cellules 30-37 â†’ `src/models.py`)

**Avant:** Code inline pour chaque modÃ¨le

**AprÃ¨s:** Classes et factories
```python
from src.models import BaselineRiskModel, ClusteringRiskModel, create_rsf_model
```

##### 6. **Optimisation Numba** (Nouveau â†’ `src/optimization.py`)

Fonctions JIT-compilÃ©es pour les calculs lourds:
- `fast_cindex()` â€” C-index parallÃ©lisÃ©
- `fast_vaf_stats()` â€” Statistiques VAF par patient
- `fast_pairwise_euclidean()` â€” Distances euclidiennes
- `fast_aggregate_by_id()` â€” AgrÃ©gation parallÃ¨le

##### 7. **Visualisation** (Nouveau â†’ `src/visualization.py`)

Fonctions de plotting standardisÃ©es:
- `plot_survival_distribution()`
- `plot_feature_importance()`
- `plot_model_comparison()`
- `plot_cluster_survival()`

##### 8. **Cellules supprimÃ©es**

Les cellules de debugging suivantes ont Ã©tÃ© retirÃ©es:
- VÃ©rification de types intermÃ©diaires
- Tests de preprocessing
- Cellules vides

#### Avantages de la nouvelle architecture

| Aspect | AmÃ©lioration |
|--------|--------------|
| **MaintenabilitÃ©** | Code modulaire, facile Ã  modifier |
| **RÃ©utilisabilitÃ©** | Modules importables dans d'autres projets |
| **Performance** | Optimisations Numba pour calculs intensifs |
| **TestabilitÃ©** | Fonctions isolÃ©es, faciles Ã  tester |
| **ReproductibilitÃ©** | Configuration centralisÃ©e dans `config.py` |

---

## ğŸ“š RÃ©fÃ©rences

- [scikit-survival Documentation](https://scikit-survival.readthedocs.io/)
- [IPCW C-index](https://scikit-survival.readthedocs.io/en/stable/api/generated/sksurv.metrics.concordance_index_ipcw.html)
- [Random Survival Forests](https://arxiv.org/abs/0811.1645)
- [Gradient Boosting Survival](https://scikit-survival.readthedocs.io/en/stable/api/generated/sksurv.ensemble.GradientBoostingSurvivalAnalysis.html)
- [Cox Proportional Hazards](https://en.wikipedia.org/wiki/Proportional_hazards_model)

---

## ğŸ¤ Contribution

Pour contribuer au projet :

1. Ouvrir `experiments.ipynb` et tester une nouvelle idÃ©e
2. Si le score s'amÃ©liore, reporter les rÃ©sultats dans `main.ipynb`
3. Mettre Ã  jour ce README avec les nouveaux scores

---

## ğŸ“„ Licence

Ce projet est dÃ©veloppÃ© dans le cadre du QRT Data Challenge 2024 en partenariat avec l'Institut Gustave Roussy.

---

<p align="center">
  <b>QRT Data Challenge 2024</b><br>
  En partenariat avec l'Institut Gustave Roussy<br><br>
  <i>Score actuel : 0.7111 | Objectif : 0.7744</i>
</p>